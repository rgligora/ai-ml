{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1e205d5d-216a-4782-abc8-bc975a4159d0",
      "metadata": {
        "id": "1e205d5d-216a-4782-abc8-bc975a4159d0"
      },
      "source": [
        "# Data Science | Lab: Image Processing\n",
        "**Table of Contents:**  <a name=\"toc\"></a>\n",
        "1. [Bag of Visual Words](#bovw)\n",
        "2. [Histogram of Visual Words](#hovw)\n",
        "3. [Image Classification](#classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "604a8c29-fb83-4e34-b794-0ec6657850a3",
      "metadata": {
        "id": "604a8c29-fb83-4e34-b794-0ec6657850a3"
      },
      "source": [
        "# Bag of Visual Words\n",
        "Analogous to the Bag of Words technique which we covered in the last lab, we will extract \"visual\" words in order to classify images in this session regarding image processing.\n",
        "\n",
        "<a name=\"bovw\"></a>\n",
        "<div style=\"width: 500px; text-align: center;\">\n",
        "    <img src=\"https://customers.pyimagesearch.com/wp-content/uploads/2015/09/bovw_image_example.jpg\"/>\n",
        "    <a href=\"https://customers.pyimagesearch.com/the-bag-of-visual-words-model/\" style=\"\">Source</a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3e062036-102b-4490-b336-39c9f61546d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e062036-102b-4490-b336-39c9f61546d3",
        "outputId": "f7441f9c-1ec0-4374-954d-2f7bef2dd68f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: opencv-contrib-python in /Users/rgligora/Library/Python/3.9/lib/python/site-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /Users/rgligora/Library/Python/3.9/lib/python/site-packages (from opencv-contrib-python) (2.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: imutils in /Users/rgligora/Library/Python/3.9/lib/python/site-packages (0.5.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install opencv-contrib-python\n",
        "%pip install imutils\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from scipy.cluster.vq import vq\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.metrics import accuracy_score\n",
        "import imutils\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a289b97-333d-4ee1-9742-c44504737e88",
      "metadata": {
        "id": "3a289b97-333d-4ee1-9742-c44504737e88"
      },
      "source": [
        "### Constructing the dataset\n",
        "- Download the dataset from moodle and extract it into the folder your notebook is in (or adapt the ``directory`` below).\n",
        "- More information on the Caltech 101 dataset, which contains images of objects belonging to 101 categories, can be found [here](https://data.caltech.edu/records/mzrjq-6wc02).\n",
        "- Before you start diving into the task, have a look at the datasets' structure and select three different types of images you want to use in this lab session.\n",
        "- Save the names of the image classes you want to use in ``use_classes``.\n",
        "- Iterate over all the directories holding images of the classes you chose and save the image paths to variable ``X_paths``.\n",
        "- For each image path in ``X_paths``, we need its corresponding label saved to ``y``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "42acfc34-0a64-406e-9e4a-df18dde42e5d",
      "metadata": {
        "id": "42acfc34-0a64-406e-9e4a-df18dde42e5d"
      },
      "outputs": [],
      "source": [
        "# Define the image source folder\n",
        "directory = \"101_ObjectCategories\"\n",
        "# Choose three different classes individually\n",
        "use_classes = [\n",
        "    \"barrel\",\n",
        "    \"cannon\",\n",
        "    \"crab\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3321ce2c-5f19-4fb5-8d3a-9f109968095d",
      "metadata": {
        "id": "3321ce2c-5f19-4fb5-8d3a-9f109968095d"
      },
      "outputs": [],
      "source": [
        "# This variable will store paths to each image ->  remains empty\n",
        "X_paths = []\n",
        "# This variable will store class id as label ->  remains empty\n",
        "y = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d7b58c76-18be-42c0-971e-ed82d06d8f06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7b58c76-18be-42c0-971e-ed82d06d8f06",
        "outputId": "b8670d86-1c42-4608-ff81-0ddfdb19c3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collected 163 image paths.\n",
            "Collected 163 labels.\n",
            "['101_ObjectCategories/barrel/image_0001.jpg', '101_ObjectCategories/barrel/image_0002.jpg', '101_ObjectCategories/barrel/image_0003.jpg', '101_ObjectCategories/barrel/image_0004.jpg', '101_ObjectCategories/barrel/image_0005.jpg', '101_ObjectCategories/barrel/image_0006.jpg', '101_ObjectCategories/barrel/image_0007.jpg', '101_ObjectCategories/barrel/image_0008.jpg', '101_ObjectCategories/barrel/image_0009.jpg', '101_ObjectCategories/barrel/image_0010.jpg', '101_ObjectCategories/barrel/image_0011.jpg', '101_ObjectCategories/barrel/image_0012.jpg', '101_ObjectCategories/barrel/image_0013.jpg', '101_ObjectCategories/barrel/image_0014.jpg', '101_ObjectCategories/barrel/image_0015.jpg', '101_ObjectCategories/barrel/image_0016.jpg', '101_ObjectCategories/barrel/image_0017.jpg', '101_ObjectCategories/barrel/image_0018.jpg', '101_ObjectCategories/barrel/image_0019.jpg', '101_ObjectCategories/barrel/image_0020.jpg', '101_ObjectCategories/barrel/image_0021.jpg', '101_ObjectCategories/barrel/image_0022.jpg', '101_ObjectCategories/barrel/image_0023.jpg', '101_ObjectCategories/barrel/image_0024.jpg', '101_ObjectCategories/barrel/image_0025.jpg', '101_ObjectCategories/barrel/image_0026.jpg', '101_ObjectCategories/barrel/image_0027.jpg', '101_ObjectCategories/barrel/image_0028.jpg', '101_ObjectCategories/barrel/image_0029.jpg', '101_ObjectCategories/barrel/image_0030.jpg', '101_ObjectCategories/barrel/image_0031.jpg', '101_ObjectCategories/barrel/image_0032.jpg', '101_ObjectCategories/barrel/image_0033.jpg', '101_ObjectCategories/barrel/image_0034.jpg', '101_ObjectCategories/barrel/image_0035.jpg', '101_ObjectCategories/barrel/image_0036.jpg', '101_ObjectCategories/barrel/image_0037.jpg', '101_ObjectCategories/barrel/image_0038.jpg', '101_ObjectCategories/barrel/image_0039.jpg', '101_ObjectCategories/barrel/image_0040.jpg', '101_ObjectCategories/barrel/image_0041.jpg', '101_ObjectCategories/barrel/image_0042.jpg', '101_ObjectCategories/barrel/image_0043.jpg', '101_ObjectCategories/barrel/image_0044.jpg', '101_ObjectCategories/barrel/image_0045.jpg', '101_ObjectCategories/barrel/image_0046.jpg', '101_ObjectCategories/barrel/image_0047.jpg', '101_ObjectCategories/cannon/image_0001.jpg', '101_ObjectCategories/cannon/image_0002.jpg', '101_ObjectCategories/cannon/image_0003.jpg', '101_ObjectCategories/cannon/image_0004.jpg', '101_ObjectCategories/cannon/image_0005.jpg', '101_ObjectCategories/cannon/image_0006.jpg', '101_ObjectCategories/cannon/image_0007.jpg', '101_ObjectCategories/cannon/image_0008.jpg', '101_ObjectCategories/cannon/image_0009.jpg', '101_ObjectCategories/cannon/image_0010.jpg', '101_ObjectCategories/cannon/image_0011.jpg', '101_ObjectCategories/cannon/image_0012.jpg', '101_ObjectCategories/cannon/image_0013.jpg', '101_ObjectCategories/cannon/image_0014.jpg', '101_ObjectCategories/cannon/image_0015.jpg', '101_ObjectCategories/cannon/image_0016.jpg', '101_ObjectCategories/cannon/image_0017.jpg', '101_ObjectCategories/cannon/image_0018.jpg', '101_ObjectCategories/cannon/image_0019.jpg', '101_ObjectCategories/cannon/image_0020.jpg', '101_ObjectCategories/cannon/image_0021.jpg', '101_ObjectCategories/cannon/image_0022.jpg', '101_ObjectCategories/cannon/image_0023.jpg', '101_ObjectCategories/cannon/image_0024.jpg', '101_ObjectCategories/cannon/image_0025.jpg', '101_ObjectCategories/cannon/image_0026.jpg', '101_ObjectCategories/cannon/image_0027.jpg', '101_ObjectCategories/cannon/image_0028.jpg', '101_ObjectCategories/cannon/image_0029.jpg', '101_ObjectCategories/cannon/image_0030.jpg', '101_ObjectCategories/cannon/image_0031.jpg', '101_ObjectCategories/cannon/image_0032.jpg', '101_ObjectCategories/cannon/image_0033.jpg', '101_ObjectCategories/cannon/image_0034.jpg', '101_ObjectCategories/cannon/image_0035.jpg', '101_ObjectCategories/cannon/image_0036.jpg', '101_ObjectCategories/cannon/image_0037.jpg', '101_ObjectCategories/cannon/image_0038.jpg', '101_ObjectCategories/cannon/image_0039.jpg', '101_ObjectCategories/cannon/image_0040.jpg', '101_ObjectCategories/cannon/image_0041.jpg', '101_ObjectCategories/cannon/image_0042.jpg', '101_ObjectCategories/cannon/image_0043.jpg', '101_ObjectCategories/crab/image_0001.jpg', '101_ObjectCategories/crab/image_0002.jpg', '101_ObjectCategories/crab/image_0003.jpg', '101_ObjectCategories/crab/image_0004.jpg', '101_ObjectCategories/crab/image_0005.jpg', '101_ObjectCategories/crab/image_0006.jpg', '101_ObjectCategories/crab/image_0007.jpg', '101_ObjectCategories/crab/image_0008.jpg', '101_ObjectCategories/crab/image_0009.jpg', '101_ObjectCategories/crab/image_0010.jpg', '101_ObjectCategories/crab/image_0011.jpg', '101_ObjectCategories/crab/image_0012.jpg', '101_ObjectCategories/crab/image_0013.jpg', '101_ObjectCategories/crab/image_0014.jpg', '101_ObjectCategories/crab/image_0015.jpg', '101_ObjectCategories/crab/image_0016.jpg', '101_ObjectCategories/crab/image_0017.jpg', '101_ObjectCategories/crab/image_0018.jpg', '101_ObjectCategories/crab/image_0019.jpg', '101_ObjectCategories/crab/image_0020.jpg', '101_ObjectCategories/crab/image_0021.jpg', '101_ObjectCategories/crab/image_0022.jpg', '101_ObjectCategories/crab/image_0023.jpg', '101_ObjectCategories/crab/image_0024.jpg', '101_ObjectCategories/crab/image_0025.jpg', '101_ObjectCategories/crab/image_0026.jpg', '101_ObjectCategories/crab/image_0027.jpg', '101_ObjectCategories/crab/image_0028.jpg', '101_ObjectCategories/crab/image_0029.jpg', '101_ObjectCategories/crab/image_0030.jpg', '101_ObjectCategories/crab/image_0031.jpg', '101_ObjectCategories/crab/image_0032.jpg', '101_ObjectCategories/crab/image_0033.jpg', '101_ObjectCategories/crab/image_0034.jpg', '101_ObjectCategories/crab/image_0035.jpg', '101_ObjectCategories/crab/image_0036.jpg', '101_ObjectCategories/crab/image_0037.jpg', '101_ObjectCategories/crab/image_0038.jpg', '101_ObjectCategories/crab/image_0039.jpg', '101_ObjectCategories/crab/image_0040.jpg', '101_ObjectCategories/crab/image_0041.jpg', '101_ObjectCategories/crab/image_0042.jpg', '101_ObjectCategories/crab/image_0043.jpg', '101_ObjectCategories/crab/image_0044.jpg', '101_ObjectCategories/crab/image_0045.jpg', '101_ObjectCategories/crab/image_0046.jpg', '101_ObjectCategories/crab/image_0047.jpg', '101_ObjectCategories/crab/image_0048.jpg', '101_ObjectCategories/crab/image_0049.jpg', '101_ObjectCategories/crab/image_0050.jpg', '101_ObjectCategories/crab/image_0051.jpg', '101_ObjectCategories/crab/image_0052.jpg', '101_ObjectCategories/crab/image_0053.jpg', '101_ObjectCategories/crab/image_0054.jpg', '101_ObjectCategories/crab/image_0055.jpg', '101_ObjectCategories/crab/image_0056.jpg', '101_ObjectCategories/crab/image_0057.jpg', '101_ObjectCategories/crab/image_0058.jpg', '101_ObjectCategories/crab/image_0059.jpg', '101_ObjectCategories/crab/image_0060.jpg', '101_ObjectCategories/crab/image_0061.jpg', '101_ObjectCategories/crab/image_0062.jpg', '101_ObjectCategories/crab/image_0063.jpg', '101_ObjectCategories/crab/image_0064.jpg', '101_ObjectCategories/crab/image_0065.jpg', '101_ObjectCategories/crab/image_0066.jpg', '101_ObjectCategories/crab/image_0067.jpg', '101_ObjectCategories/crab/image_0068.jpg', '101_ObjectCategories/crab/image_0069.jpg', '101_ObjectCategories/crab/image_0070.jpg', '101_ObjectCategories/crab/image_0071.jpg', '101_ObjectCategories/crab/image_0072.jpg', '101_ObjectCategories/crab/image_0073.jpg']\n"
          ]
        }
      ],
      "source": [
        "# TODO:\n",
        "# - iterate over the classes you chose\n",
        "# - select all image paths that are present in the respective folders corresponding to these classes\n",
        "#     - add those paths in X_paths\n",
        "# - for each image you added to X_paths this way, save an instance of its class id to y\n",
        "\n",
        "for class_id, class_name in enumerate(use_classes):\n",
        "    class_folder = os.path.join(directory, class_name)\n",
        "    if os.path.isdir(class_folder):\n",
        "        for file_name in sorted(os.listdir(class_folder)):\n",
        "            if file_name.lower().endswith(('jpg', 'jpeg', 'png')):  # Ensure valid image formats\n",
        "                image_path = os.path.join(class_folder, file_name)\n",
        "                X_paths.append(image_path)\n",
        "                y.append(class_id)  # Use class index as label\n",
        "\n",
        "# Display the collected image paths and labels\n",
        "print(f\"Collected {len(X_paths)} image paths.\")\n",
        "print(f\"Collected {len(y)} labels.\")\n",
        "print(X_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47f57e8b-bdee-4eea-a701-de5f53a27f30",
      "metadata": {
        "id": "47f57e8b-bdee-4eea-a701-de5f53a27f30"
      },
      "source": [
        "### Train/Test split\n",
        "- Perform a train/test split of the dataset (``X`` being image paths, ``y`` being corresponding labels) you constructed.\n",
        "- Use 80% of data to train the model.\n",
        "- Be sure to use stratified sampling since not all categories consist of equal number of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "59feafc0-df27-4746-bac0-2e36f908be0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59feafc0-df27-4746-bac0-2e36f908be0f",
        "outputId": "cb4f176b-7eb4-4b5f-ffc6-dcb1f47e8ace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 163\n",
            "Training samples: 130\n",
            "Test samples: 33\n",
            "Class distribution in training set: (array([0, 1, 2]), array([38, 34, 58]))\n",
            "Class distribution in test set: (array([0, 1, 2]), array([ 9,  9, 15]))\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_paths,  # List of image paths\n",
        "    y,        # List of corresponding labels\n",
        "    test_size=0.2,\n",
        "    stratify=y,  # Preserve class distribution\n",
        "    random_state=42  # For reproducibility\n",
        ")\n",
        "\n",
        "# Verify split sizes\n",
        "print(f\"Total samples: {len(X_paths)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\"Class distribution in training set: {np.unique(y_train, return_counts=True)}\")\n",
        "print(f\"Class distribution in test set: {np.unique(y_test, return_counts=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e56428-018b-4583-a5ad-8e1cc2f6a0d9",
      "metadata": {
        "id": "93e56428-018b-4583-a5ad-8e1cc2f6a0d9"
      },
      "source": [
        "### Extract SIFT Features\n",
        "- Use ``cv2`` ([OpenCV](https://docs.opencv.org/4.9.0/index.html)) to extract meaningful features from images.\n",
        "- Loop through the image paths you saved in your training set and extract the descriptors of found keypoints using the ``detectAndCompute()`` method of OpenCV's SIFT implementation as described [here](https://docs.opencv.org/4.9.0/d0/d13/classcv_1_1Feature2D.html#a8be0d1c20b08eb867184b8d74c15a677).\n",
        "- For more information on how to use SIFT in OpenCV, check this [tutorial](https://docs.opencv.org/4.9.0/da/df5/tutorial_py_sift_intro.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "472c49ff-ed12-4109-8702-798f0336c279",
      "metadata": {
        "id": "472c49ff-ed12-4109-8702-798f0336c279"
      },
      "outputs": [],
      "source": [
        "def extract_features(image_paths):\n",
        "    desc_list = []\n",
        "    sift = cv2.SIFT_create()  # Create a SIFT object\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
        "        kp, des = sift.detectAndCompute(img, None)  # Detect keypoints and compute descriptors\n",
        "        if des is not None:  # Check if descriptors were found\n",
        "            desc_list.append(des)\n",
        "        else:\n",
        "            # Handle cases where no descriptors are found\n",
        "            # For example, append an empty array or skip the image\n",
        "            print(f\"Warning: No descriptors found for {image_path}\")\n",
        "            desc_list.append(np.array([]))\n",
        "\n",
        "    return desc_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6bb61244-844b-44d4-a283-7bdee146dc76",
      "metadata": {
        "id": "6bb61244-844b-44d4-a283-7bdee146dc76"
      },
      "outputs": [],
      "source": [
        "train_desc_list = extract_features(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e09d7d76-7eb8-41e8-aebe-1cca6d1c58cd",
      "metadata": {
        "id": "e09d7d76-7eb8-41e8-aebe-1cca6d1c58cd"
      },
      "source": [
        "### Clustering\n",
        "- We want to assign similar descriptors to clusters that represent the idea of visual words in our images.\n",
        "- To do this, use the K-Means clustering method to extract clusters of descriptors from the descriptors found in all images of the training set.\n",
        "    - If you want to use [sklearn's](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) K-Means implementation, you need to parameterize it to reduce runtime (i.e., set ``n_init``, minimize ``max_iter``).\n",
        "    - You can also rely on [OpenCV](https://docs.opencv.org/4.x/d1/d5c/tutorial_py_kmeans_opencv.html), as it provides a faster implementation of K-Means.\n",
        "- In any case, we want to set ``k=100`` as the number of clusters that are to be applied to the keypoint descriptors computed by SIFT.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>Caution:</b> As we applied SIFT feature extraction to each image individually, you will have to flatten <tt>train_desc_list</tt> in order to perform the clustering correctly.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f3bb78e1-37d4-41cb-8a6e-d3f43659653d",
      "metadata": {
        "id": "f3bb78e1-37d4-41cb-8a6e-d3f43659653d"
      },
      "outputs": [],
      "source": [
        "# TODO: Stack all the descriptors of train_desc_list vertically in a numpy array\n",
        "train_descriptors = np.vstack(train_desc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3d0e2cfe-5599-49a5-bcd9-113928fd2bfc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "3d0e2cfe-5599-49a5-bcd9-113928fd2bfc",
        "outputId": "c237a74b-1e16-4550-9a8d-b648beaa20a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(max_iter=100, n_clusters=100, n_init=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(max_iter=100, n_clusters=100, n_init=10, random_state=42)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "KMeans(max_iter=100, n_clusters=100, n_init=10, random_state=42)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = 100  # Number of clusters\n",
        "#criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "#flags = cv2.KMEANS_RANDOM_CENTERS\n",
        "#compactness, labels, centers = cv2.kmeans(train_descriptors.astype(np.float32), k, None, criteria, 10, flags)\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans_model = KMeans(n_clusters=k, n_init=10, max_iter=100, random_state=42)\n",
        "kmeans_model.fit(train_descriptors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4cd1107-72da-4846-b640-f387c46ed512",
      "metadata": {
        "id": "b4cd1107-72da-4846-b640-f387c46ed512"
      },
      "source": [
        "# Histogram of Visual Words\n",
        "- In the next step, we want to apply the trained K-Means model to the descriptors of each image individually.\n",
        "- This way, we create a histogram denoting counts of feature clusters for every single image.\n",
        "- Think about it this way:\n",
        "    - Before this step, the number of descriptors found by SIFT may be different for each image.\n",
        "    - After we apply K-Means to each set of descriptors of a image, every image has a vector of length ``k`` that describes the visual words found in this image as they were computed from the whole training set.\n",
        "\n",
        "<a name=\"hovw\"></a>\n",
        "<div style=\"width: 500px; text-align: center;\">\n",
        "    <img src=\"https://miro.medium.com/max/625/1*QgI1t-7yJApi4vQigFgsLQ.jpeg\"/>\n",
        "    <a href=\"https://towardsdatascience.com/bag-of-visual-words-in-a-nutshell-9ceea97ce0fb\" style=\"\">Source</a>\n",
        "</div>\n",
        "\n",
        "### Constructing histogram with ``compute_feature_histogram(...)``\n",
        "- Suppose we set ``k=100`` and therefore computed 100 clusters from the descriptor list and we have 250 images in the training dataset.\n",
        "- ``compute_feature_histogram(...)`` should create a vector for each image (250 in this example) containing ``k=100`` elements.\n",
        "- Hence the shape of its return value will be ``(250, 100)``.\n",
        "- Remember that every image contains an arbitary number of descriptors found in it, thus we need to loop over the images separately to compute each histogram correctly.\n",
        "- Be sure to also apply the construction of histograms to your test set as well!\n",
        "- You may need to apply ``extract_features(...)`` to your testing set if you did not do so already."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1ba6c9a4-9e31-408f-b20d-d91570886918",
      "metadata": {
        "id": "1ba6c9a4-9e31-408f-b20d-d91570886918",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def compute_feature_histogram(_model, _desc_list, _k):\n",
        "    # Compute feature histogram\n",
        "    _bovw_features = np.zeros((len(_desc_list), _k), \"float32\")\n",
        "    for i, descr in enumerate(_desc_list):\n",
        "        labels = _model.predict(descr)\n",
        "        (hist, _) = np.histogram(labels, bins=range(_k + 1), density=True)\n",
        "        _bovw_features[i] = hist\n",
        "    return _bovw_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ea8bec11-4914-4055-a220-e6e31e2eb043",
      "metadata": {
        "id": "ea8bec11-4914-4055-a220-e6e31e2eb043"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_bovw_features = compute_feature_histogram(kmeans_model, train_desc_list, k) # Assuming kmeans_model is your trained KMeans model\n",
        "train_bovw_features.shape\n",
        "len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "08a46e60-c138-4b5a-aeb9-23a5475bb6a9",
      "metadata": {
        "id": "08a46e60-c138-4b5a-aeb9-23a5475bb6a9"
      },
      "outputs": [],
      "source": [
        "test_desc_list = extract_features(X_test)\n",
        "test_bovw_features = compute_feature_histogram(kmeans_model, test_desc_list, k) # Assuming kmeans_model is your trained KMeans model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bb94ec7-ec34-404f-84ab-dbebe074cefe",
      "metadata": {
        "id": "0bb94ec7-ec34-404f-84ab-dbebe074cefe"
      },
      "source": [
        "# Image Classification\n",
        "<a name=\"classification\"></a>\n",
        "- Finally, train a MinDist classifier on the training set and predict the category of each image in the test set.\n",
        "- As always, remember that in scikit-learn, MinDist is called [Nearest Centroid](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html?highlight=nearest%20centroid#sklearn.neighbors.NearestCentroid).\n",
        "- Evaluate your classifier's performance by plotting the confusion matrix!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fc3eb9fe-26ee-43f8-954f-0b2526262de9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "fc3eb9fe-26ee-43f8-954f-0b2526262de9",
        "outputId": "2cab70b6-c1fc-4ae7-a63c-52eaa21026bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5757575757575758\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAIjCAYAAACTRapjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLYElEQVR4nO3dd3RU1drH8d+EMglpEAiQCCQ0kRK6BVCKIIiIoF4pUgKKDaSFZpQWEINIFTUoRbgIYgULIr1IlY4U6RCugCBIgAADJOf9w8W8jqFkwgxnzPl+7jprOXvO7P2c3LlzH5+9zz42wzAMAQAAwDL8zA4AAAAAdxYJIAAAgMWQAAIAAFgMCSAAAIDFkAACAABYDAkgAACAxZAAAgAAWAwJIAAAgMWQAAIAAFgMCSCAm9q7d68aNmyo0NBQ2Ww2zZkzx6P9Hzp0SDabTVOnTvVov/9mdevWVd26dc0OA0A2RgII/Avs379fL730kkqUKCF/f3+FhISoVq1aGjdunC5evOjVsWNjY/XLL79o2LBhmj59uqpXr+7V8e6kDh06yGazKSQk5Lp/x71798pms8lms2nkyJFu93/06FENHjxYW7Zs8UC0AOA5Oc0OAMDNzZ07V88884zsdrvat2+vChUq6PLly1q5cqX69OmjHTt26KOPPvLK2BcvXtSaNWv0xhtv6NVXX/XKGFFRUbp48aJy5crllf5vJWfOnLpw4YK+++47tWjRwuW9GTNmyN/fX5cuXcpS30ePHlVCQoKio6NVuXLlTH9uwYIFWRoPADKLBBDwYQcPHlSrVq0UFRWlJUuWKCIiwvlely5dtG/fPs2dO9dr4588eVKSlDdvXq+NYbPZ5O/v77X+b8Vut6tWrVr69NNPMySAM2fOVJMmTfTVV1/dkVguXLigPHnyKHfu3HdkPADWxRQw4MNGjBih8+fPa/LkyS7J3zWlSpVS9+7dna+vXr2qoUOHqmTJkrLb7YqOjtbrr78uh8Ph8rno6Gg9/vjjWrlype677z75+/urRIkS+u9//+s8Z/DgwYqKipIk9enTRzabTdHR0ZL+mjq99s9/N3jwYNlsNpe2hQsX6sEHH1TevHkVFBSkMmXK6PXXX3e+f6M1gEuWLNFDDz2kwMBA5c2bV82aNdOuXbuuO96+ffvUoUMH5c2bV6GhoerYsaMuXLhw4z/sPzz77LOaN2+ezpw542xbv3699u7dq2effTbD+adPn1bv3r0VExOjoKAghYSEqHHjxtq6davznGXLlunee++VJHXs2NE5lXztOuvWrasKFSpo48aNql27tvLkyeP8u/xzDWBsbKz8/f0zXH+jRo2UL18+HT16NNPXCgASCSDg07777juVKFFCNWvWzNT5nTp10sCBA1W1alWNGTNGderUUWJiolq1apXh3H379uk///mPHnnkEY0aNUr58uVThw4dtGPHDknSU089pTFjxkiSWrdurenTp2vs2LFuxb9jxw49/vjjcjgcGjJkiEaNGqUnnnhCq1atuunnFi1apEaNGunEiRMaPHiw4uLitHr1atWqVUuHDh3KcH6LFi107tw5JSYmqkWLFpo6daoSEhIyHedTTz0lm82mr7/+2tk2c+ZM3XPPPapatWqG8w8cOKA5c+bo8ccf1+jRo9WnTx/98ssvqlOnjjMZK1u2rIYMGSJJevHFFzV9+nRNnz5dtWvXdvZz6tQpNW7cWJUrV9bYsWNVr16968Y3btw4hYeHKzY2VmlpaZKkDz/8UAsWLND48eMVGRmZ6WsFAEmSAcAnpaSkGJKMZs2aZer8LVu2GJKMTp06ubT37t3bkGQsWbLE2RYVFWVIMlasWOFsO3HihGG3241evXo52w4ePGhIMt555x2XPmNjY42oqKgMMQwaNMj4+8/KmDFjDEnGyZMnbxj3tTE+/vhjZ1vlypWNggULGqdOnXK2bd261fDz8zPat2+fYbznnnvOpc8nn3zSyJ8//w3H/Pt1BAYGGoZhGP/5z3+M+vXrG4ZhGGlpaUbhwoWNhISE6/4NLl26ZKSlpWW4DrvdbgwZMsTZtn79+gzXdk2dOnUMScaECROu+16dOnVc2ubPn29IMt58803jwIEDRlBQkNG8efNbXiMAXA8VQMBHnT17VpIUHBycqfN/+OEHSVJcXJxLe69evSQpw1rBcuXK6aGHHnK+Dg8PV5kyZXTgwIEsx/xP19YOfvPNN0pPT8/UZ44dO6YtW7aoQ4cOCgsLc7ZXrFhRjzzyiPM6/+7ll192ef3QQw/p1KlTzr9hZjz77LNatmyZjh8/riVLluj48ePXnf6V/lo36Of3189nWlqaTp065Zze3rRpU6bHtNvt6tixY6bObdiwoV566SUNGTJETz31lPz9/fXhhx9meiwA+DsSQMBHhYSESJLOnTuXqfMPHz4sPz8/lSpVyqW9cOHCyps3rw4fPuzSXqxYsQx95MuXT3/++WcWI86oZcuWqlWrljp16qRChQqpVatW+vzzz2+aDF6Ls0yZMhneK1u2rP744w+lpqa6tP/zWvLlyydJbl3LY489puDgYH322WeaMWOG7r333gx/y2vS09M1ZswYlS5dWna7XQUKFFB4eLi2bdumlJSUTI951113uXXDx8iRIxUWFqYtW7bo3XffVcGCBTP9WQD4OxJAwEeFhIQoMjJS27dvd+tz/7wJ40Zy5Mhx3XbDMLI8xrX1adcEBARoxYoVWrRokdq1a6dt27apZcuWeuSRRzKceztu51qusdvteuqppzRt2jTNnj37htU/SXrrrbcUFxen2rVr65NPPtH8+fO1cOFClS9fPtOVTumvv487Nm/erBMnTkiSfvnlF7c+CwB/RwII+LDHH39c+/fv15o1a255blRUlNLT07V3716X9t9//11nzpxx3tHrCfny5XO5Y/aaf1YZJcnPz0/169fX6NGjtXPnTg0bNkxLlizR0qVLr9v3tTh3796d4b1ff/1VBQoUUGBg4O1dwA08++yz2rx5s86dO3fdG2eu+fLLL1WvXj1NnjxZrVq1UsOGDdWgQYMMf5PMJuOZkZqaqo4dO6pcuXJ68cUXNWLECK1fv95j/QOwFhJAwIf17dtXgYGB6tSpk37//fcM7+/fv1/jxo2T9NcUpqQMd+qOHj1aktSkSROPxVWyZEmlpKRo27ZtzrZjx45p9uzZLuedPn06w2evbYj8z61promIiFDlypU1bdo0l4Rq+/btWrBggfM6vaFevXoaOnSo3nvvPRUuXPiG5+XIkSNDdfGLL77Qb7/95tJ2LVG9XrLsrn79+ik5OVnTpk3T6NGjFR0drdjY2Bv+HQHgZtgIGvBhJUuW1MyZM9WyZUuVLVvW5Ukgq1ev1hdffKEOHTpIkipVqqTY2Fh99NFHOnPmjOrUqaOff/5Z06ZNU/PmzW+4xUhWtGrVSv369dOTTz6pbt266cKFC0pKStLdd9/tchPEkCFDtGLFCjVp0kRRUVE6ceKEPvjgAxUpUkQPPvjgDft/55131LhxY9WoUUPPP/+8Ll68qPHjxys0NFSDBw/22HX8k5+fn/r373/L8x5//HENGTJEHTt2VM2aNfXLL79oxowZKlGihMt5JUuWVN68eTVhwgQFBwcrMDBQ999/v4oXL+5WXEuWLNEHH3ygQYMGObel+fjjj1W3bl0NGDBAI0aMcKs/AGAbGOBfYM+ePcYLL7xgREdHG7lz5zaCg4ONWrVqGePHjzcuXbrkPO/KlStGQkKCUbx4cSNXrlxG0aJFjfj4eJdzDOOvbWCaNGmSYZx/bj9yo21gDMMwFixYYFSoUMHInTu3UaZMGeOTTz7JsA3M4sWLjWbNmhmRkZFG7ty5jcjISKN169bGnj17Mozxz61SFi1aZNSqVcsICAgwQkJCjKZNmxo7d+50OefaeP/cZubjjz82JBkHDx684d/UMFy3gbmRG20D06tXLyMiIsIICAgwatWqZaxZs+a627d88803Rrly5YycOXO6XGedOnWM8uXLX3fMv/dz9uxZIyoqyqhatapx5coVl/N69uxp+Pn5GWvWrLnpNQDAP9kMw41V0gAAAPjXYw0gAACAxZAAAgAAWAwJIAAAgMWQAAIAAPiQFStWqGnTpoqMjJTNZtOcOXNc3jcMQwMHDlRERIQCAgLUoEGDDHvA3goJIAAAgA9JTU1VpUqV9P7771/3/REjRujdd9/VhAkTtG7dOgUGBqpRo0a6dOlSpsfgLmAAAAAfZbPZNHv2bDVv3lzSX9W/yMhI9erVS71795YkpaSkqFChQpo6depNn2L0d1QAAQAAvMjhcOjs2bMuR1af4nPw4EEdP35cDRo0cLaFhobq/vvvz9RjQ6/Jlk8C+XLrMbNDADIoHuqd59cCWRUeYjc7BMBFsTDzvpMBVV71Wt/9mhVQQkKCS9ugQYOy9GSj48ePS5IKFSrk0l6oUCHne5mRLRNAAAAAXxEfH6+4uDiXNrvd3H8BIwEEAACweW9VnN1u91jCV7hwYUnS77//roiICGf777//rsqVK2e6H9YAAgAA2GzeOzyoePHiKly4sBYvXuxsO3v2rNatW6caNWpkuh8qgAAAAD7k/Pnz2rdvn/P1wYMHtWXLFoWFhalYsWLq0aOH3nzzTZUuXVrFixfXgAEDFBkZ6bxTODNIAAEAALw4BeyuDRs2qF69es7X19YPxsbGaurUqerbt69SU1P14osv6syZM3rwwQf1448/yt/fP9NjZMt9ALkLGL6Iu4Dha7gLGL7G1LuAq/f0Wt8XN4zxWt9ZRQUQAADAw2v1fJ3v1DsBAABwR1ABBAAA8KE1gHeCta4WAAAAVAABAACstgaQBBAAAIApYAAAAGRnVAABAAAsNgVMBRAAAMBiqAACAACwBhAAAADZGRVAAAAA1gACAAAgO6MCCAAAYLE1gCSAAAAATAEDAAAgO6MCCAAAYLEpYGtdLQAAAKgAAgAAUAEEAABAtkYFEAAAwI+7gAEAAJCNUQEEAACw2BpAEkAAAAA2ggYAAEB2RgUQAADAYlPA1rpaAAAAUAEEAABgDSAAAACyNSqAAAAArAEEAABAdkYFEAAAwGJrAEkAAQAAmAIGAABAdkYFEAAAwGJTwFQAAQAALIYKIAAAAGsAAQAAkJ1RAQQAAGANIAAAALIzEkAAAACbn/cON507d049evRQVFSUAgICVLNmTa1fv96jl8sUMAAAgA/dBNKpUydt375d06dPV2RkpD755BM1aNBAO3fu1F133eWRMXznagEAACzu4sWL+uqrrzRixAjVrl1bpUqV0uDBg1WqVCklJSV5bBwqgAAAAF68CcThcMjhcLi02e122e32DOdevXpVaWlp8vf3d2kPCAjQypUrPRYTFUAAAAAvSkxMVGhoqMuRmJh43XODg4NVo0YNDR06VEePHlVaWpo++eQTrVmzRseOHfNYTDbDMAyP9eYjvtzquT8Q4CnFQwPNDgFwER6SsfoAmKlYmHnfyYBmH3qt7zOfd8h0BVCS9u/fr+eee04rVqxQjhw5VLVqVd19993auHGjdu3a5ZGYmAIGAADwopsle9dTsmRJLV++XKmpqTp79qwiIiLUsmVLlShRwmMxMQUMAABgs3nvyKLAwEBFRETozz//1Pz589WsWTOPXS4VQAAAAB8yf/58GYahMmXKaN++ferTp4/uuecedezY0WNjkAACAAD40D6AKSkpio+P1//+9z+FhYXp6aef1rBhw5QrVy6PjUECCAAA4EPPAm7RooVatGjh1TF8J90FAADAHUEFEAAAWJ7NhyqAdwIVQAAAAIsxrQIYFxeX6XNHjx7txUgAAIDVWa0CaFoCuHnz5kydZ7X/QgAAALzNtARw6dKlZg0NAADgymL1Jp9aA7hv3z7Nnz9fFy9elCRlw8cUAwAAmM4nEsBTp06pfv36uvvuu/XYY4/p2LFjkqTnn39evXr1Mjk6AACQ3dlsNq8dvsgnEsCePXsqV65cSk5OVp48eZztLVu21I8//mhiZAAAwAqslgD6xD6ACxYs0Pz581WkSBGX9tKlS+vw4cMmRQUAAJA9+UQCmJqa6lL5u+b06dOy2+0mRAQAAKzEVyt13uITU8APPfSQ/vvf/zpf22w2paena8SIEapXr56JkQEAAGQ/PlEBHDFihOrXr68NGzbo8uXL6tu3r3bs2KHTp09r1apVZocHAACyOatVAH0iAaxQoYL27Nmj9957T8HBwTp//ryeeuopdenSRREREWaHZ2nL58zQgpkTVfOxp9WkQ1ezw4FFLfzuSy2a+5X++P2vHQLuiiqhp9o8r8r31jI5MljVp9MmaeXyxTpy+KDsdrvKxVRWp849VDSquNmhAZliegJ45coVPfroo5owYYLeeOMNs8PB3/xv369av/A7FY4qaXYosLiw8IJq9dyrKnxXUckwtGLhXI0a3FuJ73+iItF8P3Hnbdu8QU883UplypZXWlqapkx4V6/1eFmTZs5WQEDGNe34F7BWAdD8NYC5cuXStm3bzA4D/+C4dEGfj39TzV/qrYDAILPDgcVVe6C2qtxXSxF3FVNEkSi17NhZ/v55tPfX7WaHBotKHDtBjZo0U3SJUipZuoz69B+qE8ePae+vO80ODcgU0xNASWrbtq0mT55sdhj4m+8mjVOZKg+oVMXqZocCuEhPS9PqZQvkcFxU6bIxZocDSJJSz5+XJAWHhJocCbKKfQBNcPXqVU2ZMkWLFi1StWrVFBgY6PL+6NGjTYrMmratWqyjB/folcQJZocCOCUf3KdBPZ7TlcuX5R8QoJ4D31GRqBJmhwUoPT1dSWNHqHzFKipesrTZ4QCZ4hMJ4Pbt21W1alVJ0p49e1zeu1Xm7HA45HA4XNquXHYoV272D8yKM3+c0PdT39Nz/UfyN4RPiSwSpcQPZujChfP6+afFmjBysAa88yFJIEw3fuQwHTqwT2M+nGp2KLgNvlqp8xabYRiGmQGkpaVp1apViomJUb58+dz+/ODBg5WQkODS9sxLcWrxSm9PhWgpO3/+STNGDpCf3/+vDkhPT3eWsRNmLpSfXw4TI/z3Kh4aeOuTkGnD+nVWocgi6tT9dbND+dcKD+Ff8m7X+JFvac1PSzUq6WNFRBa59QdwU8XCzPtOhrWb6bW+T09/1mt9Z5XpFcAcOXKoYcOG2rVrV5YSwPj4eMXFxbm0zd192lPhWU7JmGrqNnKKS9tXSW8rPLKYajdrTfIHn2EYhq5euWx2GLAowzD03qhErVq+RCM/mEzyh38d0xNA6a99AA8cOKDixd3fP8lut2d4XFyu3KmeCs1y7AF5VKiY65Rabru/8gSHZGgH7pRZU95TpXtrqkB4YV28eEGrl/6oXds26rVh480ODRY1fuQwLVkwTwlvj1OePIE6feoPSVJgYJDs/v4mR4essNoUsE8kgG+++aZ69+6toUOHXvcmkJCQEJMiA+ALzp75U0nvDNaZ038oT54gFS1eSq8NG6+YavebHRos6ruvP5ck9e7ynEt77/5D1ahJMzNCAtxi+hpASS7rzf6egRuGIZvNprS0NLf6+3LrMY/FBngKawDha1gDCF9j5hrA/LGfeq3vU9Nae63vrPKJCuDSpUvNDgEAAMAyfCIBrFOnjtkhAAAAC2MNoIkuXLig5ORkXb7semdfxYoVTYoIAAAg+/GJBPDkyZPq2LGj5s2bd9333V0DCAAA4A6rVQB94lnAPXr00JkzZ7Ru3ToFBAToxx9/1LRp01S6dGl9++23ZocHAACyOZ4FbIIlS5bom2++UfXq1eXn56eoqCg98sgjCgkJUWJiopo0aWJ2iAAAANmGT1QAU1NTVbBgQUlSvnz5dPLkSUlSTEyMNm3aZGZoAADACmxePHyQTySAZcqU0e7duyVJlSpV0ocffqjffvtNEyZMUEREhMnRAQAAZC8+MQXcvXt3HTv21+bNgwYN0qOPPqpPPvlEuXPn1rRp00yODgAAZHe+ulbPW3wiAWzbtq3zn6tWrarDhw/r119/VbFixVSgQAETIwMAAMh+fGIKWJImT56sChUqyN/fX/ny5VP79u01Z84cs8MCAAAWwF3AJhg4cKBGjx6trl27qkaNGpKkNWvWqGfPnkpOTtaQIUNMjhAAACD78IkEMCkpSRMnTlTr1v//sOQnnnhCFStWVNeuXUkAAQCAV/lqpc5bfCIBvHLliqpXr56hvVq1arp69aoJEQEAACuxWgLoE2sA27Vrp6SkpAztH330kdq0aWNCRAAAANmXaRXAuLg45z/bbDZNmjRJCxYs0AMPPCBJWrdunZKTk9W+fXuzQgQAAFZhrQKgeQng5s2bXV5Xq1ZNkrR//35JUoECBVSgQAHt2LHjjscGAABghrS0NA0ePFiffPKJjh8/rsjISHXo0EH9+/f36DS1aQng0qVLzRoaAADAha+sAXz77beVlJSkadOmqXz58tqwYYM6duyo0NBQdevWzWPj+MRNIAAAAJBWr16tZs2aqUmTJpKk6Ohoffrpp/r55589Oo5P3AQCAABgJm9uBO1wOHT27FmXw+FwXDeOmjVravHixdqzZ48kaevWrVq5cqUaN27s0eslAQQAAPCixMREhYaGuhyJiYnXPfe1115Tq1atdM899yhXrlyqUqWKevTo4fFdUZgCBgAAlufNNYDx8fEuu59Ikt1uv+65n3/+uWbMmKGZM2eqfPny2rJli3r06KHIyEjFxsZ6LCYSQAAAAC/eA2K322+Y8P1Tnz59nFVASYqJidHhw4eVmJjo0QSQKWAAAAAfceHCBfn5uaZnOXLkUHp6ukfHoQIIAAAsz1e2gWnatKmGDRumYsWKqXz58tq8ebNGjx6t5557zqPjkAACAAD4iPHjx2vAgAHq3LmzTpw4ocjISL300ksaOHCgR8chAQQAAJbnKxXA4OBgjR07VmPHjvXqOKwBBAAAsBgqgAAAwPJ8pQJ4p1ABBAAAsBgqgAAAwPKsVgEkAQQAALBW/scUMAAAgNVQAQQAAJZntSlgKoAAAAAWQwUQAABYHhVAAAAAZGtUAAEAgOVZrABIBRAAAMBqqAACAADLs9oaQBJAAABgeRbL/5gCBgAAsBoqgAAAwPKsNgVMBRAAAMBiqAACAADLs1gBkAogAACA1VABBAAAlufnZ60SIBVAAAAAi6ECCAAALM9qawBJAAEAgOWxDQwAAACyNSqAAADA8ixWAKQCCAAAYDVUAAEAgOWxBhAAAADZGhVAAABgeVQAAQAAkK1RAQQAAJZnsQIgCSAAAABTwAAAAMjWqAACAADLs1gBkAogAACA1VABBAAAlscaQAAAAGRrVAABAIDlWawASAUQAADAaqgAAgAAy2MNIAAAALI1EkAAAGB5Npv3DndER0fLZrNlOLp06eLR62UKGAAAWJ6vTAGvX79eaWlpztfbt2/XI488omeeecaj45AAAgAA+Ijw8HCX18OHD1fJkiVVp04dj45DAggAACzPmwVAh8Mhh8Ph0ma322W322/6ucuXL+uTTz5RXFycxyuU2TIBvK9omNkhABlM23TE7BAAF7FVi5odAmAJiYmJSkhIcGkbNGiQBg8efNPPzZkzR2fOnFGHDh08HlO2TAABAADc4c01gPHx8YqLi3Npu1X1T5ImT56sxo0bKzIy0uMxkQACAAB4UWame//p8OHDWrRokb7++muvxEQCCAAALM9HbgJ2+vjjj1WwYEE1adLEK/2zDyAAAIAPSU9P18cff6zY2FjlzOmdWh0VQAAAYHm+sg+gJC1atEjJycl67rnnvDYGCSAAALA8H8r/1LBhQxmG4dUxmAIGAACwGCqAAADA8nxpCvhOoAIIAABgMVQAAQCA5VEBBAAAQLZGBRAAAFiexQqAVAABAACshgogAACwPKutASQBBAAAlmex/I8pYAAAAKuhAggAACzPalPAVAABAAAshgogAACwPIsVAKkAAgAAWA0VQAAAYHl+FisBUgEEAACwGCqAAADA8ixWACQBBAAAYBsYAAAAZGtUAAEAgOX5WasASAUQAADAaqgAAgAAy2MNIAAAALI1KoAAAMDyLFYApAIIAABgNVQAAQCA5dlkrRIgCSAAALA8toEBAABAtkYFEAAAWB7bwAAAACBbowIIAAAsz2IFQCqAAAAAVkMFEAAAWJ6fxUqAVAABAAAshgogAACwPIsVAEkAAQAArLYNTKYSwG3btmW6w4oVK2Y5GAAAAHhfphLAypUry2azyTCM675/7T2bzaa0tDSPBggAAOBtFisAZi4BPHjwoLfjAAAAwB2SqQQwKirK23EAAACYhm1gMmH69OmqVauWIiMjdfjwYUnS2LFj9c0333g0OAAAAKv57bff1LZtW+XPn18BAQGKiYnRhg0bPDqG2wlgUlKS4uLi9Nhjj+nMmTPONX958+bV2LFjPRocAADAnWDz4uGOP//8U7Vq1VKuXLk0b9487dy5U6NGjVK+fPlu8wpdub0NzPjx4zVx4kQ1b95cw4cPd7ZXr15dvXv39mhwAAAAVvL222+raNGi+vjjj51txYsX9/g4blcADx48qCpVqmRot9vtSk1N9UhQAAAAd5LNZvPa4XA4dPbsWZfD4XBcN45vv/1W1atX1zPPPKOCBQuqSpUqmjhxosev1+0EsHjx4tqyZUuG9h9//FFly5b1REwAAAB3lJ/Ne0diYqJCQ0NdjsTExOvGceDAASUlJal06dKaP3++XnnlFXXr1k3Tpk3z6PW6PQUcFxenLl266NKlSzIMQz///LM+/fRTJSYmatKkSR4NDgAA4N8uPj5ecXFxLm12u/2656anp6t69ep66623JElVqlTR9u3bNWHCBMXGxnosJrcTwE6dOikgIED9+/fXhQsX9OyzzyoyMlLjxo1Tq1atPBYYAADAneLNR8HZ7fYbJnz/FBERoXLlyrm0lS1bVl999ZVHY8rSs4DbtGmjNm3a6MKFCzp//rwKFizo0aAAAACsqFatWtq9e7dL2549ezy+J3OWEkBJOnHihDNAm82m8PDwLPWTmpqq4cOHa/HixTpx4oTS09Nd3j9w4EBWQwQAAMgUX9kHumfPnqpZs6beeusttWjRQj///LM++ugjffTRRx4dx+0E8Ny5c+rcubM+/fRTZ7KWI0cOtWzZUu+//75CQ0Pd6q9Tp05avny52rVrp4iICK+WYAEAAHzZvffeq9mzZys+Pl5DhgxR8eLFNXbsWLVp08aj42RpDeDmzZs1d+5c1ahRQ5K0Zs0ade/eXS+99JJmzZrlVn/z5s3T3LlzVatWLXdDAQAA8AhfKkA9/vjjevzxx706htsJ4Pfff6/58+frwQcfdLY1atRIEydO1KOPPup2APny5VNYWJjbnwMAAEDWuL0PYP78+a87zRsaGpqlx5QMHTpUAwcO1IULF9z+LAAAgCd4cx9AX+R2BbB///6Ki4vT9OnTVbhwYUnS8ePH1adPHw0YMMDtAEaNGqX9+/erUKFCio6OVq5cuVze37Rpk9t9AgAAuMOXpoDvhEwlgFWqVHH5w+zdu1fFihVTsWLFJEnJycmy2+06efKkXnrpJbcCaN68uVvnAwAA4PZkKgH0ZpI2aNAgr/UNAACQGdaq/2UyAbwTSdrGjRu1a9cuSVL58uVVpUoVr48JAABgRVneCNpTTpw4oVatWmnZsmXKmzevJOnMmTOqV6+eZs2aleUNpgEAADLLz2JrAN2+CzgtLU0jR47Ufffdp8KFCyssLMzlcFfXrl117tw57dixQ6dPn9bp06e1fft2nT17Vt26dXO7PwAAANyc2wlgQkKCRo8erZYtWyolJUVxcXF66qmn5Ofnp8GDB7sdwI8//qgPPvhAZcuWdbaVK1dO77//vubNm+d2fwAAAO6y2bx3+CK3E8AZM2Zo4sSJ6tWrl3LmzKnWrVtr0qRJGjhwoNauXet2AOnp6Rm2fpGkXLlyZXguMAAAAG6f2wng8ePHFRMTI0kKCgpSSkqKpL8eWzJ37ly3A3j44YfVvXt3HT161Nn222+/qWfPnqpfv77b/QEAALjLZrN57fBFbieARYoU0bFjxyRJJUuW1IIFCyRJ69evl91udzuA9957T2fPnlV0dLRKliypkiVLqnjx4jp79qzGjx/vdn8AAAC4ObfvAn7yySe1ePFi3X///eratavatm2ryZMnKzk5WT179nQ7gKJFi2rTpk1atGiRfv31V0lS2bJl1aBBA7f7AgAAyAofLdR5jc0wDON2Oli7dq1Wr16t0qVLq2nTpp6K67Ykn3aYHcK/2qfTJmnl8sU6cvig7Ha7ysVUVqfOPVQ0qrjZof2rTdt0xOwQ/rW2zp2hX36Y6dIWUqiInhj4oUkRZQ+xVYuaHcK/Fr+T3lEszP2ZRE955audXus76elyXus7q257H8AHHnhADzzwgE6cOKG33npLr7/+utt9LF68WIsXL9aJEycy3PgxZcqU2w0Rbtq2eYOeeLqVypQtr7S0NE2Z8K5e6/GyJs2crYCAPGaHB4sKjYhSg65vOl/bcuQwMRpYHb+T+Lfz2EbQx44d04ABA9xOABMSEjRkyBBVr15dERERPrtY0koSx05wed2n/1A981hd7f11pypWqW5SVLA6Pz8/BYS6v9co4A38TmY/Vks/TH8SyIQJEzR16lS1a9fO7FBwA6nnz0uSgkNCTY4EVnb25FF99Xo75ciZSwWKl1WVZrEKDCtodliAJH4n8e9jegJ4+fJl1axZ0+wwcAPp6elKGjtC5StWUfGSpc0OBxZVILqMarbrqZBCRXQx5bS2/TBTC0b31eP9P1Auf6bbYC5+J7MHq81Aur0NjKd16tRJM2fOvPWJN+BwOHT27FmXw+HgJhBPGT9ymA4d2Kc3hr5tdiiwsLvKV1dU1YeU767iiixXTQ93TtDli6k6vOkns0MD+J3Ev1KmK4BxcXE3ff/kyZNZCuDSpUv66KOPtGjRIlWsWDHDU0FGjx59088nJiYqISHBpa1H3zfUs9+ALMWD/zd+5Ftat2qFRiV9rPCChc0OB3DKnSdIwQXv0rmTx8wOBRbH72T2YXpF7A7LdAK4efPmW55Tu3ZttwPYtm2bKleuLEnavn27y3uZKcfGx8dnSE5/T3U7DPyNYRh6b1SiVi1fopEfTFZEZBGzQwJcXLl0Uef/OKaAkIfNDgUWxe8k/u0ynQAuXbrUKwHcbr92uz3DE0jOXGUK+HaMHzlMSxbMU8Lb45QnT6BOn/pDkhQYGCS7v7/J0cGKNn49SUVi7ldgWEFdTDmlrXNnyObnp+jqdcwODRbF72T2Y7U1gKbfBALf893Xn0uSend5zqW9d/+hatSkmRkhweIunDmllR+PkCP1rPyDQhVesrwe7T1a/sHccQlz8DuZ/fhZK/8zPwFMTU3V8OHDb7gR9IEDB0yKzLoWrtlmdgiAi4ee62d2CIALfifxb2d6AtipUyctX75c7dq1YyNoAABgCiqAd9i8efM0d+5c1apVy+xQAAAALMH0BDBfvnwKC+PxTgAAwDxWm4HM0rY3P/30k9q2basaNWrot99+kyRNnz5dK1eudLuvoUOHauDAgbpw4UJWQgEAAICb3K4AfvXVV2rXrp3atGmjzZs3O5+6kZKSorfeeks//PCDW/2NGjVK+/fvV6FChRQdHZ1hI+hNmza5GyIAAIBbWAN4C2+++aYmTJig9u3ba9asWc72WrVq6c0333Q7gObNm7v9GQAAAGSd2wng7t27r/vEj9DQUJ05c8btAAYNGuT2ZwAAADzJYksA3V8DWLhwYe3bty9D+8qVK1WiRAmPBAUAAHAn+dlsXjt8kdsJ4AsvvKDu3btr3bp1stlsOnr0qGbMmKHevXvrlVdecTuAtLQ0jRw5Uvfdd58KFy6ssLAwlwMAAACe5fYU8Guvvab09HTVr19fFy5cUO3atWW329W7d2917drV7QASEhI0adIk9erVS/3799cbb7yhQ4cOac6cORo4cKDb/QEAALgrS9ui/IvZDMMwsvLBy5cva9++fTp//rzKlSunoKCgLAVQsmRJvfvuu2rSpImCg4O1ZcsWZ9vatWs1c+ZMt/tMPu3IUiyAN03bdMTsEAAXsVWLmh0C4KJYmN20sV//YY/X+n7rsbu91ndWZXkj6Ny5c6tcuXK3HcDx48cVExMjSQoKClJKSook6fHHH9eAAQNuu38AAIBb8dGlel7jdgJYr169m+6WvWTJErf6K1KkiI4dO6ZixYqpZMmSWrBggapWrar169fLbjfv3wQAAACyK7cTwMqVK7u8vnLlirZs2aLt27crNjbW7QCefPJJLV68WPfff7+6du2qtm3bavLkyUpOTlbPnj3d7g8AAMBdvnq3rre4nQCOGTPmuu2DBw/W+fPn3Q5g+PDhzn9u2bKloqKitHr1apUuXVpNmzZ1uz8AAADcnMduemnbtq2mTJni9ucSExNdPvfAAw8oLi5OJ0+e1Ntvv+2p8AAAAG7IZvPe4Ys8lgCuWbNG/v7+bn/uww8/1D333JOhvXz58powYYInQgMAALgpP5v3DncMHjxYNpvN5bhennS73J4Cfuqpp1xeG4ahY8eOacOGDVm6a/f48eOKiIjI0B4eHq5jx4653R8AAMC/Wfny5bVo0SLn65w5s7xpyw253WNoaKjLaz8/P5UpU0ZDhgxRw4YN3Q6gaNGiWrVqlYoXL+7SvmrVKkVGRrrdHwAAgLt86SaQnDlzqnDhwt4dw52T09LS1LFjR8XExChfvnweCeCFF15Qjx49dOXKFT388MOSpMWLF6tv377q1auXR8YAAAAwi8PhkMPh+pAKu91+w+3u9u7dq8jISPn7+6tGjRpKTExUsWLFPBqTW2sAc+TIoYYNG+rMmTMeC6BPnz56/vnn1blzZ5UoUUIlSpRQ165d1a1bN8XHx3tsHAAAgBvx5k0giYmJCg0NdTkSExOvG8f999+vqVOn6scff1RSUpIOHjyohx56SOfOnfPs9br7KLjq1avr7bffVv369T0ayPnz57Vr1y4FBASodOnSt7UJNI+Cgy/iUXDwNTwKDr7GzEfBDV20z2t9932oqFsVwL87c+aMoqKiNHr0aD3//PMei8ntNYBvvvmmevfuraFDh6patWoKDAx0eT8kJCRLgQQFBenee+/N0mcBAABuh7t367ojs8ne9eTNm1d333239u3zbIKa6SngIUOGKDU1VY899pi2bt2qJ554QkWKFFG+fPmUL18+5c2b12PrAgEAAPDXDOn+/fuvu2PK7ch0BTAhIUEvv/yyli5d6tEAAAAAzGaTb9wF3Lt3bzVt2lRRUVE6evSoBg0apBw5cqh169YeHSfTCeC1pYJ16tTxaAAAAABm8+YUsDv+97//qXXr1jp16pTCw8P14IMPau3atQoPD/foOG6tAbT50B45AAAA2c2sWbPuyDhuJYB33333LZPA06dP31ZAAAAAd5qvVADvFLcSwISEhAxPAgEAAMC/i1sJYKtWrVSwYEFvxQIAAGAKqy1zy/Q2MFb7wwAAAGRXbt8FDAAAkN2wBvAG0tPTvRkHAAAA7hC3HwUHAACQ3VhtpRsJIAAAsDw/i2WAmb4JBAAAANkDFUAAAGB5VrsJhAogAACAxVABBAAAlmexJYBUAAEAAKyGCiAAALA8P1mrBEgFEAAAwGKoAAIAAMuz2hpAEkAAAGB5bAMDAACAbI0KIAAAsDweBQcAAIBsjQogAACwPIsVAKkAAgAAWA0VQAAAYHmsAQQAAEC2RgUQAABYnsUKgCSAAAAAVpsStdr1AgAAWB4VQAAAYHk2i80BUwEEAACwGCqAAADA8qxV/6MCCAAAYDlUAAEAgOWxETQAAACyNSqAAADA8qxV/yMBBAAAsNyTQJgCBgAAsBgqgAAAwPLYCBoAAADZGhVAAABgeVariFntegEAACyPCiAAALA81gACAADAJwwfPlw2m009evTwaL9UAAEAgOX5Yv1v/fr1+vDDD1WxYkWP900FEAAAwMecP39ebdq00cSJE5UvXz6P908CCAAALM9ms3ntcDgcOnv2rMvhcDhuGk+XLl3UpEkTNWjQwCvXmy2ngAuG2M0OAcigbHig2SEALsrU72V2CICLi5vfM21sb1bEEhMTlZCQ4NI2aNAgDR48+Lrnz5o1S5s2bdL69eu9FlO2TAABAAB8RXx8vOLi4lza7PbrF6uOHDmi7t27a+HChfL39/daTCSAAADA8ry5DYzdbr9hwvdPGzdu1IkTJ1S1alVnW1pamlasWKH33ntPDodDOXLkuO2YSAABAAB8RP369fXLL7+4tHXs2FH33HOP+vXr55HkTyIBBAAA8JltYIKDg1WhQgWXtsDAQOXPnz9D++3gLmAAAACLoQIIAAAsz5efBLds2TKP90kFEAAAwGKoAAIAAMvz85lVgHcGCSAAALA8X54C9gamgAEAACyGCiAAALA8m8WmgKkAAgAAWAwVQAAAYHmsAQQAAEC2RgUQAABYntW2gaECCAAAYDFUAAEAgOVZbQ0gCSAAALA8qyWATAEDAABYDBVAAABgeWwEDQAAgGyNCiAAALA8P2sVAKkAAgAAWA0VQAAAYHmsAQQAAEC2RgUQAABYntX2ASQBBAAAlscUMAAAALI1KoAAAMDy2AYGAAAA2RoVQAAAYHmsAQQAAEC2RgUQAABYntW2gaECCAAAYDFUAAEAgOVZrABIAggAAOBnsTlgpoABAAAshgogAACwPGvV/6gAAgAAWA4VQAAAAIuVAKkAAgAAWAwVQAAAYHk8Cg4AAADZGhVAAABgeRbbBpAEEAAAwGL5H1PAAAAAVkMCCAAAYPPi4YakpCRVrFhRISEhCgkJUY0aNTRv3rzbvboMSAABAAB8RJEiRTR8+HBt3LhRGzZs0MMPP6xmzZppx44dHh2HNYAAAMDyfGUbmKZNm7q8HjZsmJKSkrR27VqVL1/eY+OQAAIAAHiRw+GQw+FwabPb7bLb7Tf9XFpamr744gulpqaqRo0aHo2JKWAAAGB5Npv3jsTERIWGhrociYmJN4zll19+UVBQkOx2u15++WXNnj1b5cqV8+j1UgEEAADwovj4eMXFxbm03az6V6ZMGW3ZskUpKSn68ssvFRsbq+XLl3s0CSQBBAAAlufNFYCZme79u9y5c6tUqVKSpGrVqmn9+vUaN26cPvzwQ4/FRAIIAADgG/eAXFd6enqGNYS3iwQQAADAR8THx6tx48YqVqyYzp07p5kzZ2rZsmWaP3++R8chAQQAAJbnK9vAnDhxQu3bt9exY8cUGhqqihUrav78+XrkkUc8Og4JIAAAgI+YPHnyHRmHBBAAAFiezTcKgHcM+wACAABYDBVAAABgeRYrAFIBBAAAsBoqgAAAABYrAZIAAgAAy/OVbWDuFJ+aAjYMQ4ZhmB0GAABAtuYTCeDkyZNVoUIF+fv7y9/fXxUqVNCkSZPMDgsAAFiEzea9wxeZPgU8cOBAjR49Wl27dlWNGjUkSWvWrFHPnj2VnJysIUOGmBwhAABA9mJ6ApiUlKSJEyeqdevWzrYnnnhCFStWVNeuXUkAAQCA1/looc5rTJ8CvnLliqpXr56hvVq1arp69aoJEQEAAGRvpieA7dq1U1JSUob2jz76SG3atDEhIgAAYDk2Lx4+yJQp4Li4OOc/22w2TZo0SQsWLNADDzwgSVq3bp2Sk5PVvn17M8IDAADI1kxJADdv3uzyulq1apKk/fv3S5IKFCigAgUKaMeOHXc8NkgbN6zX1CmTtWvndp08eVJj3n1fD9dvYHZYgNPyOTO0YOZE1XzsaTXp0NXscGABtaqWVM/2DVS1XDFFhIeqRc+P9N2ybS7nDHiliTo+WVN5gwO0ZusBdXvrM+1PPmlSxHCX1fYBNCUBXLp0qRnDIpMuXrygMmXKqPlTTyuu+6tmhwO4+N++X7V+4XcqHFXS7FBgIYEBdv2y5zf995s1+mz0ixne79WhgTq3rqMXBk7Xod9OaWDnx/Xd+11U5ek35bjMenb4HtPvAobvefChOnrwoTpmhwFk4Lh0QZ+Pf1PNX+qtZV9PNzscWMiCVTu1YNXOG77f5dl6envifH2/7BdJUqcB/9XhRYl6ol4lfTF/450KE7fBV/fr8xafSAA3bNigzz//XMnJybp8+bLLe19//bVJUQHwNd9NGqcyVR5QqYrVSQDhM6Lvyq+I8FAtWfers+3s+Utav/2Q7q8YTQL4L2Gx/M/8u4BnzZqlmjVrateuXZo9e7auXLmiHTt2aMmSJQoNDTU7PAA+YtuqxTp6cI8aPvuC2aEALgoXCJEknTh9zqX9xKlzKpQ/xIyQgFsyvQL41ltvacyYMerSpYuCg4M1btw4FS9eXC+99JIiIiJu+XmHwyGHw+HSZuSwy263eytkAHfYmT9O6Pup7+m5/iOVKzf/2wbgBRYrAZpeAdy/f7+aNGkiScqdO7dSU1Nls9nUs2dPffTRR7f8fGJiokJDQ12Od95O9HbYAO6gowd2KzXlT73f7wUNaPWwBrR6WAd3btWaeV9rQKuHlZ6eZnaIsLDjf5yVJBUMC3ZpL5g/WL+fOmtGSMAtmV4BzJcvn86d+6tsftddd2n79u2KiYnRmTNndOHChVt+Pj4+3mVfQemvCiCA7KNkTDV1GznFpe2rpLcVHllMtZu1lp9fDpMiA6RDv53SsZMpqnd/GW3b85skKTjQX/dWiNbEL1aaHB0yi21g7rDatWtr4cKFiomJ0TPPPKPu3btryZIlWrhwoerXr3/Lz9vtGad7L3HH/W25kJqq5ORk5+vf/vc//bprl0JDQxURGWliZLAqe0AeFSpWwqUtt91feYJDMrQD3hAYkFsli4Y7X0fflV8V775Lf569oCPH/9T7M5eqX6dHtS/5pA79dkqDOjfRsZMp+nbpVhOjBm7M9ATwvffe06VLlyRJb7zxhnLlyqXVq1fr6aefVv/+/U2Ozpp27NiuTh3//yksI0f8NaX+RLMnNfSt4WaFBQCmqVouSgsmdXe+HtH7aUnS9G/X6sVBn2jU1EXKE2DXe/1bK29wgFZv2a8nunzAHoD/IlbbBsZmGIZh1uBXr17VzJkz1ahRIxUqVMhj/VIBhC/6fscxs0MAXLTrMMzsEAAXFze/Z9rYu4/fetlZVpUpnMdrfWeVqTeB5MyZUy+//LKzAggAAGAGmxcPX2T6XcD33XeftmzZYnYYAADAyiyWAZq+BrBz586Ki4vTkSNHVK1aNQUGBrq8X7FiRZMiAwAAyJ5MTwBbtWolSerWrZuzzWazyTAM2Ww2paWxvxcAAPAutoG5ww4ePGh2CAAAAJZiegI4c+ZMFSpUSM8995xL+5QpU3Ty5En169fPpMgAAIBVWG0bGNNvAvnwww91zz33ZGgvX768JkyYYEJEAAAA2ZvpFcDjx48rIiIiQ3t4eLiOHWPfNAAA4H0WKwCaXwEsWrSoVq1alaF91apViuSxYwAAAB5negXwhRdeUI8ePXTlyhU9/PDDkqTFixerb9++6tWrl8nRAQAAS7BYCdD0BLBPnz46deqUOnfurMuXL0uS/P391a9fP8XHx5scHQAAsAK2gbnDbDab3n77bQ0YMEC7du1SQECASpcuLbvdbnZoAAAA2ZLpCeA1QUFBuvfee80OAwAAWBDbwAAAACBb85kKIAAAgFksVgCkAggAAGA1JIAAAAA2Lx5uSExM1L333qvg4GAVLFhQzZs31+7du2/36jIgAQQAAPARy5cvV5cuXbR27VotXLhQV65cUcOGDZWamurRcVgDCAAALM9X9gH88ccfXV5PnTpVBQsW1MaNG1W7dm2PjUMCCAAALM+b28A4HA45HA6XNrvdnqk9j1NSUiRJYWFhHo2JKWAAAAAvSkxMVGhoqMuRmJh4y8+lp6erR48eqlWrlipUqODRmKgAAgAAy/PmBHB8fLzi4uJc2jJT/evSpYu2b9+ulStXejwmEkAAAAAvyux079+9+uqr+v7777VixQoVKVLE4zGRAAIAAMvzlUfBGYahrl27avbs2Vq2bJmKFy/ulXFIAAEAAHxEly5dNHPmTH3zzTcKDg7W8ePHJUmhoaEKCAjw2DjcBAIAAOAjO0EnJSUpJSVFdevWVUREhPP47LPPbvsK/44KIAAAgI8wDOOOjEMCCAAALM9X1gDeKSSAAADA8iyW/7EGEAAAwGqoAAIAAMuz2hQwFUAAAACLoQIIAAAsz2axVYBUAAEAACyGCiAAAIC1CoBUAAEAAKyGCiAAALA8ixUASQABAADYBgYAAADZGhVAAABgeWwDAwAAgGyNCiAAAIC1CoBUAAEAAKyGCiAAALA8ixUAqQACAABYDRVAAABgeVbbB5AEEAAAWB7bwAAAACBbowIIAAAsz2pTwFQAAQAALIYEEAAAwGJIAAEAACyGNYAAAMDyWAMIAACAbI0KIAAAsDyr7QNIAggAACyPKWAAAABka1QAAQCA5VmsAEgFEAAAwGqoAAIAAFisBEgFEAAAwGKoAAIAAMuz2jYwVAABAAAshgogAACwPPYBBAAAQLZGBRAAAFiexQqAJIAAAABWywCZAgYAALAYEkAAAGB5Ni/+x10rVqxQ06ZNFRkZKZvNpjlz5nj8ekkAAQAAfEhqaqoqVaqk999/32tjsAYQAABYni9tA9O4cWM1btzYq2OQAAIAAHiRw+GQw+FwabPb7bLb7SZFlE0TQP9seVV3nsPhUGJiouLj4039kmYX/6kUYXYI/3p8Jz3rP5vfMzuEbIHvZfbgzdxh8JuJSkhIcGkbNGiQBg8e7L1Bb8FmGIZh2ujwaWfPnlVoaKhSUlIUEhJidjgA30n4JL6XuJXbqQDabDbNnj1bzZs392hM1MoAAAC8yOzp3uvhLmAAAACLoQIIAADgQ86fP699+/Y5Xx88eFBbtmxRWFiYihUr5pExSABxQ3a7XYMGDfK5sjWsi+8kfBHfS3jahg0bVK9ePefruLg4SVJsbKymTp3qkTG4CQQAAMBiWAMIAABgMSSAAAAAFkMCCAAAYDEkgNlQ3bp11aNHD7PDcPK1eADgTuI3EL6IBBAAAMBiSABxS4Zh6OrVqxnaL1++bEI0AOAbrly5YnYIQJaRAGZTV69e1auvvqrQ0FAVKFBAAwYM0LUdf6ZPn67q1asrODhYhQsX1rPPPqsTJ044P7ts2TLZbDbNmzdP1apVk91u18qVK1W3bl29+uqr6tGjhwoUKKBGjRpJkrZv367GjRsrKChIhQoVUrt27fTHH3+Yct3wDenp6RoxYoRKlSolu92uYsWKadiwYZKkfv366e6771aePHlUokQJDRgwwOX/SAcPHqzKlStr+vTpio6OVmhoqFq1aqVz5845z6lbt666deumvn37KiwsTIULF87wUPXk5GQ1a9ZMQUFBCgkJUYsWLfT777+7NQ6s50bf3UOHDslms+mzzz5TnTp15O/vrxkzZujUqVNq3bq17rrrLuXJk0cxMTH69NNPM/R7s99kwAwkgNnUtGnTlDNnTv38888aN26cRo8erUmTJkn6699ahw4dqq1bt2rOnDk6dOiQOnTokKGP1157TcOHD9euXbtUsWJFZ7+5c+fWqlWrNGHCBJ05c0YPP/ywqlSpog0bNujHH3/U77//rhYtWtzJy4WPiY+P1/DhwzVgwADt3LlTM2fOVKFChSRJwcHBmjp1qnbu3Klx48Zp4sSJGjNmjMvn9+/frzlz5uj777/X999/r+XLl2v48OEu50ybNk2BgYFat26dRowYoSFDhmjhwoWS/vo/8WbNmun06dNavny5Fi5cqAMHDqhly5ZujwNrudl3V/rrd7F79+7atWuXGjVqpEuXLqlatWqaO3eutm/frhdffFHt2rXTzz//7NLvzX6TAVMYyHbq1KljlC1b1khPT3e29evXzyhbtux1z1+/fr0hyTh37pxhGIaxdOlSQ5IxZ86cDP1WqVLFpW3o0KFGw4YNXdqOHDliSDJ2797t/Fz37t1v97LwL3H27FnDbrcbEydOzNT577zzjlGtWjXn60GDBhl58uQxzp4962zr06ePcf/99ztf16lTx3jwwQdd+rn33nuNfv36GYZhGAsWLDBy5MhhJCcnO9/fsWOHIcn4+eefMz0OrOVm392DBw8akoyxY8fesp8mTZoYvXr1cr529zcZuBOoAGZTDzzwgGw2m/N1jRo1tHfvXqWlpWnjxo1q2rSpihUrpuDgYNWpU0fSX1Nmf1e9evUM/VarVs3l9datW7V06VIFBQU5j3vuuUfSX9UVWM+uXbvkcDhUv379677/2WefqVatWipcuLCCgoLUv3//DN+96OhoBQcHO19HRES4LFOQ5KxKX++cXbt2qWjRoipatKjz/XLlyilv3rzatWuXW+PAOm713ZUy/i6mpaVp6NChiomJUVhYmIKCgjR//vwM3+mb/SYDZuBZwBZz6dIlNWrUSI0aNdKMGTMUHh6u5ORkNWrUKMNNHYGBgRk+/8+28+fPq2nTpnr77bcznBsREeHZ4PGvEBAQcMP31qxZozZt2ighIUGNGjVSaGioZs2apVGjRrmclytXLpfXNptN6enpbp9zK57oA9nHzb671/zzN/Cdd97RuHHjNHbsWMXExCgwMFA9evTgJjn4PBLAbGrdunUur9euXavSpUvr119/1alTpzR8+HBndWTDhg1ZHqdq1ar66quvFB0drZw5+TpBKl26tAICArR48WJ16tTJ5b3Vq1crKipKb7zxhrPt8OHDHo+hbNmyOnLkiI4cOeL8nu/cuVNnzpxRuXLlPD4esoebfXdvZNWqVWrWrJnatm0r6a/1p3v27MnwPbvRb3KOHDk8EzzgJqaAs6nk5GTFxcVp9+7d+vTTTzV+/Hh1795dxYoVU+7cuTV+/HgdOHBA3377rYYOHZrlcbp06aLTp0+rdevWWr9+vfbv36/58+erY8eOTG1YlL+/v/r166e+ffvqv//9r/bv36+1a9dq8uTJKl26tJKTkzVr1izt379f7777rmbPnu3xGBo0aKCYmBi1adNGmzZt0s8//6z27durTp06113aAEg3/+7eSOnSpbVw4UKtXr1au3bt0ksvveRyt/k1N/pNBsxCySabat++vS5evKj77rtPOXLkUPfu3fXiiy/KZrNp6tSpev311/Xuu++qatWqGjlypJ544oksjRMZGalVq1apX79+atiwoRwOh6KiovToo4/Kz49/v7CqAQMGKGfOnBo4cKCOHj2qiIgIvfzyy3r++efVs2dPvfrqq3I4HGrSpIkGDBiQYQuX22Wz2fTNN9+oa9euql27tvz8/PToo49q/PjxHh0H2c+Nvrs30r9/fx04cECNGjVSnjx59OKLL6p58+ZKSUlxOe9Gv8mAWWyGwUZEAAAAVkKJBgAAwGJIAAEAACyGBBAAAMBiSAABAAAshgQQAADAYkgAAQAALIYEEAAAwGJIAAEAACyGBBCAx3To0EHNmzd3vq5bt6569Ohxx+NYtmyZbDabzpw547Ux/nmtWXEn4gSA6yEBBLK5Dh06yGazyWazKXfu3CpVqpSGDBmiq1even3sr7/+OtPPmr7TyVB0dLTGjh17R8YCAF/Ds4ABC3j00Uf18ccfy+Fw6IcfflCXLl2UK1cuxcfHZzj38uXLyp07t0fGDQsL80g/AADPogIIWIDdblfhwoUVFRWlV155RQ0aNNC3334r6f+nMocNG6bIyEiVKVNGknTkyBG1aNFCefPmVVhYmJo1a6ZDhw45+0xLS1NcXJzy5s2r/Pnzq2/fvvrno8X/OQXscDjUr18/FS1aVHa7XaVKldLkyZN16NAh1atXT5KUL18+2Ww2dejQQZKUnp6uxMREFS9eXAEBAapUqZK+/PJLl3F++OEH3X333QoICFC9evVc4syKtLQ0Pf/8884xy5Qpo3Hjxl333ISEBIWHhyskJEQvv/yyLl++7HwvM7EDgBmoAAIWFBAQoFOnTjlfL168WCEhIVq4cKEk6cqVK2rUqJFq1Kihn376STlz5tSbb76pRx99VNu2bVPu3Lk1atQoTZ06VVOmTFHZsmU1atQozZ49Ww8//PANx23fvr3WrFmjd999V5UqVdLBgwf1xx9/qGjRovrqq6/09NNPa/fu3QoJCVFAQIAkKTExUZ988okmTJig0qVLa8WKFWrbtq3Cw8NVp04dHTlyRE899ZS6dOmiF198URs2bFCvXr1u6++Tnp6uIkWK6IsvvlD+/Pm1evVqvfjii4qIiFCLFi1c/m7+/v5atmyZDh06pI4dOyp//vwaNmxYpmIHANMYALK12NhYo1mzZoZhGEZ6erqxcOFCw263G71793a+X6hQIcPhcDg/M336dKNMmTJGenq6s83hcBgBAQHG/PnzDcMwjIiICGPEiBHO969cuWIUKVLEOZZhGEadOnWM7t27G4ZhGLt37zYkGQsXLrxunEuXLjUkGX/++aez7dKlS0aePHmM1atXu5z7/PPPG61btzYMwzDi4+ONcuXKubzfr1+/DH39U1RUlDFmzJgbvv9PXbp0MZ5++mnn69jYWCMsLMxITU11tiUlJRlBQUFGWlpapmK/3jUDwJ1ABRCwgO+//15BQUG6cuWK0tPT9eyzz2rw4MHO92NiYlzW/W3dulX79u1TcHCwSz+XLl3S/v37lZKSomPHjun+++93vpczZ05Vr149wzTwNVu2bFGOHDncqnzt27dPFy5c0COPPOLSfvnyZVWpUkWStGvXLpc4JKlGjRqZHuNG3n//fU2ZMkXJycm6ePGiLl++rMqVK7ucU6lSJeXJk8dl3PPnz+vIkSM6f/78LWMHALOQAAIWUK9ePSUlJSl37tyKjIxUzpyu/9MPDAx0eX3+/HlVq1ZNM2bMyNBXeHh4lmK4NqXrjvPnz0uS5s6dq7vuusvlPbvdnqU4MmPWrFnq3bu3Ro0apRo1aig4OFjvvPOO1q1bl+k+zIodADKDBBCwgMDAQJUqVSrT51etWlWfffaZChYsqJCQkOueExERoXXr1ql27dqSpKtXr2rjxo2qWrXqdc+PiYlRenq6li9frgYNGmR4/1oFMi0tzdlWrlw52e12JScn37ByWLZsWecNLdesXbv21hd5E6tWrVLNmjXVuXNnZ9v+/fsznLd161ZdvHjRmdyuXbtWQUFBKlq0qMLCwm4ZOwCYhbuAAWTQpk0bFShQQM2aNdNPP/2kgwcPatmyZerWrZv+97//SZK6d++u4cOHa86cOfr111/VuXPnm+7hFx0drdjYWD333HOaM2eOs8/PP/9ckhQVFSWbzabvv/9eJ0+e1Pnz5xUcHKzevXurZ8+emjZtmvbv369NmzZp/PjxmjZtmiTp5Zdf1t69e9WnTx/t3r1bM2fO1NSpUzN1nb/99pu2bNnicvz5558qXbq0NmzYoPnz52vPnj0aMGCA1q9fn+Hzly9f1vPPP6+dO3fqhx9+0KBBg/Tqq6/Kz88vU7EDgGnMXoQIwLv+fhOIO+8fO3bMaN++vVGgQAHDbrcbJUqUMF544QUjJSXFMIy/bvro3r27ERISYuTNm9eIi4sz2rdvf8ObQAzDMC5evGj07NnTiIiIMHLnzm2UKlXKmDJlivP9IUOGGIULFzZsNpsRGxtrGMZfN66MHTvWKFOmjJErVy4jPDzcaNSokbF8+XLn57777jujVKlSht1uNx566CFjypQpmboJRFKGY/r06calS5eMDh06GKGhoUbevHmNV155xXjttdeMSpUqZfi7DRw40MifP78RFBRkvPDCC8alS5ec59wqdm4CAWAWm2HcYMU2AAAAsiWmgAEAACyGBBAAAMBiSAABAAAshgQQAADAYkgAAQAALIYEEAAAwGJIAAEAACyGBBAAAMBiSAABAAAshgQQAADAYkgAAQAALOb/ADJd1B5Hs2AoAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO: implement image classification steps described above!\n",
        "\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ... (previous code for feature extraction, clustering, and histogram computation) ...\n",
        "\n",
        "# Train the Nearest Centroid classifier\n",
        "classifier = NearestCentroid()\n",
        "classifier.fit(train_bovw_features, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(test_bovw_features)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=use_classes, yticklabels=use_classes)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e0196ad-995d-40f6-8174-bcac529d2319",
      "metadata": {
        "id": "0e0196ad-995d-40f6-8174-bcac529d2319"
      },
      "source": [
        "## Homework Assignment\n",
        "\n",
        "Extend your code to include the following:\n",
        "1. Extend your dataset to use 5 different individually chosen categories of images.\n",
        "2. Set up a grid search for at least three different ``k`` for K-Means and two different distance ``metric``s for MinDist.\n",
        "3. Evaluate the grid with 3-fold (stratified) cross validation with ``accuracy`` as the scoring method.\n",
        "4. Check if histogram normalization has an influence on your results by including it as an option in your grid search.\n",
        "5. Plot the confusion matrix for the test dataset using the best setting according to the grid search.\n",
        "6. Document your findings (see final comment in section Moodle Upload on the topics to include in your findings).\n",
        "\n",
        "\n",
        "## Moodle Upload\n",
        "This is an **indivdual** assignment, meaning that you are graded individually. If you have collaborated with colleagues during the lab, make sure to state **all** of their names at the beginning of the document. The final document **must** exhibit individual efforts (structure, variable settings, reasoning, interpretation) despite some inherent similarities.\n",
        "\n",
        "Upload your notebook as ``firstname_lastname_ip.html`` to Moodle.\n",
        "\n",
        "Make sure to consider the following:\n",
        "* Have all your import statements in one single cell at the top of the notebook.\n",
        "* Remove unnecessary code.\n",
        "* Include a markdown cell at the end where you:\n",
        "    * give a short overview of what your notebook is about\n",
        "    * be sure to describe BOVW in your own words: Which steps are necessary? How does it relate to the BoW-concept from NLP? What are \"words\" and \"documents\" in this context?\n",
        "    * describe and interpret your settings and justify your choices\n",
        "    * analyze the final/best results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "62a24230-4008-463c-a6df-7546f79eed30",
      "metadata": {
        "id": "62a24230-4008-463c-a6df-7546f79eed30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k=50, metric=euclidean, normalize=True, accuracy=0.5391\n",
            "k=50, metric=euclidean, normalize=False, accuracy=0.5391\n",
            "k=50, metric=manhattan, normalize=True, accuracy=0.5548\n",
            "k=50, metric=manhattan, normalize=False, accuracy=0.5548\n",
            "k=100, metric=euclidean, normalize=True, accuracy=0.6163\n",
            "k=100, metric=euclidean, normalize=False, accuracy=0.6163\n",
            "k=100, metric=manhattan, normalize=True, accuracy=0.6011\n",
            "k=100, metric=manhattan, normalize=False, accuracy=0.6011\n",
            "k=150, metric=euclidean, normalize=True, accuracy=0.6082\n",
            "k=150, metric=euclidean, normalize=False, accuracy=0.6082\n",
            "k=150, metric=manhattan, normalize=True, accuracy=0.5930\n",
            "k=150, metric=manhattan, normalize=False, accuracy=0.5930\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "compute_feature_histogram() takes 3 positional arguments but 4 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m best_kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m], n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     38\u001b[0m best_kmeans\u001b[38;5;241m.\u001b[39mfit(train_descriptors)\n\u001b[0;32m---> 39\u001b[0m train_bovw_features \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_feature_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_kmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_desc_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnormalize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m test_sift_features \u001b[38;5;241m=\u001b[39m extract_features(X_test)\n\u001b[1;32m     41\u001b[0m test_bovw_features \u001b[38;5;241m=\u001b[39m compute_feature_histogram(best_kmeans, test_sift_features, best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m], best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "\u001b[0;31mTypeError\u001b[0m: compute_feature_histogram() takes 3 positional arguments but 4 were given"
          ]
        }
      ],
      "source": [
        "train_descriptors = np.vstack([desc for desc in train_desc_list if desc is not None])\n",
        "\n",
        "# Grid search parameters\n",
        "k_values = [50, 100, 150]  # Different cluster sizes\n",
        "metrics = [\"euclidean\", \"manhattan\"]  # Different distance metrics\n",
        "normalize_options = [True, False]  # Check impact of histogram normalization\n",
        "\n",
        "# Perform Grid Search\n",
        "best_score = 0\n",
        "best_params = {}\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10, max_iter=300, random_state=42)\n",
        "    kmeans.fit(train_descriptors)\n",
        "    \n",
        "    for metric in metrics:\n",
        "        for normalize in normalize_options:\n",
        "            # Compute histograms\n",
        "            train_bovw_features = compute_feature_histogram(kmeans, train_desc_list, k, normalize)\n",
        "            \n",
        "            # Cross-validation\n",
        "            skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "            clf = NearestCentroid(metric=metric)\n",
        "            scores = []\n",
        "            for train_idx, val_idx in skf.split(train_bovw_features, y_train):\n",
        "                clf.fit(train_bovw_features[train_idx], np.array(y_train)[train_idx])\n",
        "                scores.append(accuracy_score(np.array(y_train)[val_idx], clf.predict(train_bovw_features[val_idx])))\n",
        "            \n",
        "            avg_score = np.mean(scores)\n",
        "            print(f\"k={k}, metric={metric}, normalize={normalize}, accuracy={avg_score:.4f}\")\n",
        "            \n",
        "            # Store best parameters\n",
        "            if avg_score > best_score:\n",
        "                best_score = avg_score\n",
        "                best_params = {\"k\": k, \"metric\": metric, \"normalize\": normalize}\n",
        "\n",
        "# Train with best settings\n",
        "best_kmeans = KMeans(n_clusters=best_params[\"k\"], n_init=10, max_iter=300, random_state=42)\n",
        "best_kmeans.fit(train_descriptors)\n",
        "train_bovw_features = compute_feature_histogram(best_kmeans, train_desc_list, best_params[\"k\"], best_params[\"normalize\"])\n",
        "test_sift_features = extract_features(X_test)\n",
        "test_bovw_features = compute_feature_histogram(best_kmeans, test_sift_features, best_params[\"k\"], best_params[\"normalize\"])\n",
        "\n",
        "clf = NearestCentroid(metric=best_params[\"metric\"])\n",
        "clf.fit(train_bovw_features, y_train)\n",
        "y_pred = clf.predict(test_bovw_features)\n",
        "\n",
        "# Evaluate final model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=use_classes, yticklabels=use_classes)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Document findings\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Final Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
